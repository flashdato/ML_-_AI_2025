{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f06f48a4-d83e-4dfa-8625-ef9eb359a513",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast # For safely evaluating string representations of lists/dicts\n",
    "\n",
    "# Load the datasets\n",
    "movies = pd.read_csv('../data/tmdb_5000_movies.csv')\n",
    "credits = pd.read_csv('../data/tmdb_5000_credits.csv')\n",
    "\n",
    "# Merge them on the 'title' column\n",
    "movies = movies.merge(credits, on='title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53c49f2f-d6de-4510-889e-203245c0e45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll use: genres, id, keywords, title, overview, cast, crew\n",
    "movies = movies[['movie_id', 'title', 'overview', 'genres', 'keywords', 'cast', 'crew']]\n",
    "\n",
    "# Drop rows with missing values\n",
    "movies.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2d14213-67e0-42d3-8e79-13cfc1cc8d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to extract names from the stringified JSON\n",
    "def convert(obj):\n",
    "    L = []\n",
    "    for i in ast.literal_eval(obj):\n",
    "        L.append(i['name'])\n",
    "    return L\n",
    "\n",
    "movies['genres'] = movies['genres'].apply(convert)\n",
    "movies['keywords'] = movies['keywords'].apply(convert)\n",
    "\n",
    "# For 'cast', let's just take the top 3 actors\n",
    "def convert3(obj):\n",
    "    L = []\n",
    "    counter = 0\n",
    "    for i in ast.literal_eval(obj):\n",
    "        if counter != 3:\n",
    "            L.append(i['name'])\n",
    "            counter += 1\n",
    "        else:\n",
    "            break\n",
    "    return L\n",
    "\n",
    "movies['cast'] = movies['cast'].apply(convert3)\n",
    "\n",
    "# For 'crew', we only want the director's name\n",
    "def fetch_director(obj):\n",
    "    L = []\n",
    "    for i in ast.literal_eval(obj):\n",
    "        if i['job'] == 'Director':\n",
    "            L.append(i['name'])\n",
    "            break\n",
    "    return L\n",
    "\n",
    "movies['crew'] = movies['crew'].apply(fetch_director)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb73a1aa-f520-47ab-b45b-f46fa1f34cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   movie_id                                     title  \\\n",
      "0     19995                                    Avatar   \n",
      "1       285  Pirates of the Caribbean: At World's End   \n",
      "2    206647                                   Spectre   \n",
      "3     49026                     The Dark Knight Rises   \n",
      "4     49529                               John Carter   \n",
      "\n",
      "                                                tags  \n",
      "0  in the 22nd century, a paraplegic marine is di...  \n",
      "1  captain barbossa, long believed to be dead, ha...  \n",
      "2  a cryptic message from bondâ€™s past sends him o...  \n",
      "3  following the death of district attorney harve...  \n",
      "4  john carter is a war-weary, former military ca...  \n"
     ]
    }
   ],
   "source": [
    "# Make 'overview' a list of words\n",
    "movies['overview'] = movies['overview'].apply(lambda x: x.split())\n",
    "\n",
    "# Remove spaces between words in other columns to create unique tags (e.g., \"James Cameron\" -> \"JamesCameron\")\n",
    "movies['genres'] = movies['genres'].apply(lambda x: [i.replace(\" \", \"\") for i in x])\n",
    "movies['keywords'] = movies['keywords'].apply(lambda x: [i.replace(\" \", \"\") for i in x])\n",
    "movies['cast'] = movies['cast'].apply(lambda x: [i.replace(\" \", \"\") for i in x])\n",
    "movies['crew'] = movies['crew'].apply(lambda x: [i.replace(\" \", \"\") for i in x])\n",
    "\n",
    "# Combine everything into a 'tags' column\n",
    "movies['tags'] = movies['overview'] + movies['genres'] + movies['keywords'] + movies['cast'] + movies['crew']\n",
    "\n",
    "# Create a new DataFrame with just the essential info\n",
    "# ---- THE FIX IS HERE ----\n",
    "# We explicitly create a copy to avoid the SettingWithCopyWarning\n",
    "new_df = movies[['movie_id', 'title', 'tags']].copy()\n",
    "\n",
    "# Convert the list of tags back into a string\n",
    "new_df['tags'] = new_df['tags'].apply(lambda x: \" \".join(x))\n",
    "\n",
    "# Convert to lowercase\n",
    "new_df['tags'] = new_df['tags'].apply(lambda x: x.lower())\n",
    "\n",
    "# Let's check the first row to see our final 'tags' column\n",
    "print(new_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffa23afd-5613-451c-bb24-e08e8ddb4ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# TF-IDF Vectorization\n",
    "# We use TF-IDF which is better than simple CountVectorizer for this task.\n",
    "# max_features=5000 means we'll consider the 5000 most frequent words.\n",
    "tfidf = TfidfVectorizer(max_features=5000, stop_words='english')\n",
    "vectors = tfidf.fit_transform(new_df['tags']).toarray()\n",
    "\n",
    "# Calculate Cosine Similarity\n",
    "# This creates a matrix where each movie is compared to every other movie.\n",
    "similarity = cosine_similarity(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2b6dac3-f0ef-4f00-b5ab-6b94f8ed1455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the DataFrame (which contains movie titles)\n",
    "pickle.dump(new_df.to_dict(), open('static/movie_dict.pkl', 'wb'))\n",
    "\n",
    "# Save the similarity matrix\n",
    "pickle.dump(similarity, open('static/similarity.pkl', 'wb'))\n",
    "\n",
    "print(\"Model saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affa286d-1ef5-4496-90d5-377c3357df51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
